{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML-HW1-BoranIslamoglu-24205.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTfDIhAYYjaX",
        "colab_type": "text"
      },
      "source": [
        "# Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGi6c-0uZSeB",
        "colab_type": "code",
        "outputId": "77c9ee43-91b7-4104-adb6-a057cedd4833",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFpeyxi8aqIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You can find the data under https://drive.google.com/drive/folders/1e550az93U3_kfRBbVY5PZnMKYwGYmHqi?usp=sharing\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train_data = pd.read_csv (\"/content/drive/My Drive/HW1/train_data.csv\")\n",
        "train_label = pd.read_csv (\"/content/drive/My Drive/HW1/train_label.csv\")\n",
        "\n",
        "test_data = pd.read_csv (\"/content/drive/My Drive/HW1/test_data.csv\")\n",
        "test_label = pd.read_csv (\"/content/drive/My Drive/HW1/test_label.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZXqzZlXBIN0",
        "colab_type": "code",
        "outputId": "5a31d208-97e5-43e5-ad1f-ab57417ab5c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# show random samples from the training data\n",
        "\n",
        "p=pd.DataFrame(train_data)\n",
        "p.sample(5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>duration</th>\n",
              "      <th>credit_amount</th>\n",
              "      <th>installment_commitment</th>\n",
              "      <th>residence_since</th>\n",
              "      <th>age</th>\n",
              "      <th>existing_credits</th>\n",
              "      <th>num_dependents</th>\n",
              "      <th>f_worker</th>\n",
              "      <th>checking_status_&lt;0</th>\n",
              "      <th>checking_status_&gt;=200</th>\n",
              "      <th>checking_status_no checking</th>\n",
              "      <th>credit_history_critical/other existing credit</th>\n",
              "      <th>credit_history_delayed previously</th>\n",
              "      <th>credit_history_existing paid</th>\n",
              "      <th>credit_history_no credits/all paid</th>\n",
              "      <th>purpose_domestic appliance</th>\n",
              "      <th>purpose_education</th>\n",
              "      <th>purpose_furniture/equipment</th>\n",
              "      <th>purpose_new car</th>\n",
              "      <th>purpose_other</th>\n",
              "      <th>purpose_radio/tv</th>\n",
              "      <th>purpose_repairs</th>\n",
              "      <th>purpose_retraining</th>\n",
              "      <th>purpose_used car</th>\n",
              "      <th>savings_status_500&lt;=X&lt;1000</th>\n",
              "      <th>savings_status_&lt;100</th>\n",
              "      <th>savings_status_&gt;=1000</th>\n",
              "      <th>savings_status_no known savings</th>\n",
              "      <th>employment_4&lt;=X&lt;7</th>\n",
              "      <th>employment_&lt;1</th>\n",
              "      <th>employment_&gt;=7</th>\n",
              "      <th>employment_unemployed</th>\n",
              "      <th>personal_status_male div/sep</th>\n",
              "      <th>personal_status_male mar/wid</th>\n",
              "      <th>personal_status_male single</th>\n",
              "      <th>other_parties_guarantor</th>\n",
              "      <th>other_parties_none</th>\n",
              "      <th>property_magnitude_life insurance</th>\n",
              "      <th>property_magnitude_no known property</th>\n",
              "      <th>property_magnitude_real estate</th>\n",
              "      <th>other_payment_plans_none</th>\n",
              "      <th>other_payment_plans_stores</th>\n",
              "      <th>housing_own</th>\n",
              "      <th>housing_rent</th>\n",
              "      <th>job_skilled</th>\n",
              "      <th>job_unemp/unskilled non res</th>\n",
              "      <th>job_unskilled resident</th>\n",
              "      <th>own_telephone_yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>364</th>\n",
              "      <td>365</td>\n",
              "      <td>18</td>\n",
              "      <td>2473</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>320</td>\n",
              "      <td>15</td>\n",
              "      <td>3643</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>402</td>\n",
              "      <td>18</td>\n",
              "      <td>1887</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>28</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>648</th>\n",
              "      <td>649</td>\n",
              "      <td>24</td>\n",
              "      <td>947</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>211</td>\n",
              "      <td>9</td>\n",
              "      <td>3074</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>33</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  duration  ...  job_unskilled resident  own_telephone_yes\n",
              "364  365        18  ...                       0                  0\n",
              "319  320        15  ...                       1                  0\n",
              "401  402        18  ...                       0                  0\n",
              "648  649        24  ...                       0                  0\n",
              "210  211         9  ...                       0                  0\n",
              "\n",
              "[5 rows x 49 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQIVU4-zXpE_",
        "colab_type": "text"
      },
      "source": [
        "# Train Decision Tree with default parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLznLl_lXYZf",
        "colab_type": "code",
        "outputId": "9bceb2b1-37eb-4d4b-8df8-90dbacce533c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Train decision tree using the whole training data with **entropy** criteria\n",
        "\n",
        "gcc = DecisionTreeClassifier(criterion='entropy')\n",
        "gcc = gcc.fit(train_data, train_label)\n",
        "\n",
        "# Estimate the prediction of test data\n",
        "test_pred = gcc.predict(test_data)\n",
        "\n",
        "# Calculate accuracy of test data\n",
        "from sklearn.metrics import accuracy_score\n",
        "TestAcc = accuracy_score(test_label,test_pred)\n",
        "print(\"Testing Accuracy = %.5f%%\" % (TestAcc * 100))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy = 66.18357%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqgNZYUMXv8X",
        "colab_type": "text"
      },
      "source": [
        "# FineTune Decision Tree parameters\n",
        "\n",
        "1- Spliting dataset into train and validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWJxk-zjy0Kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split training data to 70% training and 30% validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(train_data, train_label, test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqws-kTZYHoG",
        "colab_type": "text"
      },
      "source": [
        "2- FineTune minimum sample split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1DvpmCCJXTb",
        "colab_type": "code",
        "outputId": "c09d1968-0aca-4b42-91fc-e6ffaf57778e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "min_samples_splits = range(2, 100)\n",
        "\n",
        "train_results = []\n",
        "val_results = []\n",
        "for min_samples_split in min_samples_splits:\n",
        "  \n",
        "  # Fit the tree using the 70% portion of the training data\n",
        "  dt = DecisionTreeClassifier(min_samples_split=min_samples_split, criterion='entropy')\n",
        "  dt.fit(x_train, y_train)\n",
        "  \n",
        "  # Evaluate on Training set\n",
        "  train_pred = dt.predict(x_train)\n",
        "  train_acc = accuracy_score(y_train, train_pred)\n",
        "  train_results.append(train_acc)\n",
        "   \n",
        "  # Evaluate on Validation set\n",
        "  val_pred = dt.predict(x_val)\n",
        "  val_acc = accuracy_score(y_val, val_pred)\n",
        "  val_results.append(val_acc)\n",
        "  \n",
        "# Ploting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(min_samples_splits, train_results, 'b')\n",
        "plt.plot(min_samples_splits, val_results,'r')\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akVAE3MbL7bE",
        "colab_type": "code",
        "outputId": "875974c8-2e9a-4a2b-da76-f09ee52261ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Choose the best minimum split sample based on the plot\n",
        "Best_minSampl = 82\n",
        "\n",
        "# Train decision tree using the full training data and the best minimum split sample\n",
        "newdt = DecisionTreeClassifier(min_samples_split=Best_minSampl, criterion='entropy')\n",
        "newdt.fit(train_data, train_label)\n",
        "\n",
        "# Estimate the prediction of the test data\n",
        "test_pred = newdt.predict(test_data)\n",
        "\n",
        "# Calculate accuracy of test data\n",
        "TestAcc = accuracy_score(test_label,test_pred)\n",
        "print(\"Testing Accuracy = %.5f%%\" % (TestAcc * 100))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy = 71.49758%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VciE0lfYKhya",
        "colab_type": "text"
      },
      "source": [
        "# Now, apply the same procedure but using KNN instead of decision tree \n",
        "\n",
        "# For finetuning, find the best value of K to use with this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdBaXNKoLBcL",
        "colab_type": "code",
        "outputId": "61f88174-fe3e-45fc-b66e-a31361f161ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# initialize the values of k to be a list of odd numbers between 1 and 30\n",
        "kVals = range(1, 30, 2)\n",
        "\n",
        "# Save the accuracies of each value of kVal in [accuracies] variable\n",
        "# hint: you can use accuracies.append(...) function inside the loop\n",
        "accuracies = []\n",
        "\n",
        "# loop over values of k for the k-Nearest Neighbor classifier\n",
        "for k in kVals:\n",
        "  # Follow what we did in decision tree part\n",
        "  model = KNeighborsClassifier(n_neighbors=k)\n",
        "  model.fit(x_train, y_train.values.ravel())\n",
        "  score = model.score(x_val, y_val)\n",
        "  accuracies.append(score)\n",
        "\n",
        "bestK = np.argmax(accuracies)\n",
        "\n",
        "# Train KNN using the full training data with the best K that you found\n",
        "\n",
        "newModel = KNeighborsClassifier(n_neighbors=kVals[bestK])\n",
        "newModel.fit(train_data,train_label.values.ravel())\n",
        "prediction = newModel.predict(test_data)\n",
        "TestAccuracy = accuracy_score(test_label, prediction)\n",
        "print(\"Testing Accuracy = %.5f%%\" % (TestAccuracy * 100))\n",
        "\n",
        "# Testing\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy = 70.04831%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMEdOIlJQBin",
        "colab_type": "text"
      },
      "source": [
        "# Bonus\n",
        "\n",
        "# Apply gridsearch using decision tree on any hyperparameter(s) of your choice, you have to beat your previous obtained accuracies to get the bonus\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-9TxVbXQCw7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e1d1ec15-6fad-400e-b76f-9686e0900285"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "grid = GridSearchCV(estimator = gcc, cv = 10, param_grid=[\n",
        "  {'max_depth': [None,1,3,5,7,9], 'criterion': ['gini','entropy'], 'splitter':['random'], 'min_samples_split': range(50,90)}\n",
        " ])\n",
        "grid.fit(train_data,train_label)\n",
        "gprediction = grid.predict(test_data)\n",
        "TestAccuracy = accuracy_score(test_label, gprediction)\n",
        "print(\"Testing Accuracy = %.5f%%\" % (TestAccuracy * 100))\n",
        "print(grid.best_params_)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy = 73.91304%\n",
            "{'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 54, 'splitter': 'random'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VCH10cwnAU-",
        "colab_type": "text"
      },
      "source": [
        "# Report: Write a summary of your approach to this problem; this should be like an abstract of a paper or the executive summary (you aim for clarity and passing on information, not going to details about known facts such as what decision trees are, assuming they are known to people in your research area).\n",
        "\n",
        "Must include statements such as:\n",
        "\n",
        "\n",
        "*   Include the problem definition: 1-2 lines\n",
        "*   Talk about train/val/test sets, size and how split.\n",
        "*   State what your test results are with the chosen method, parameters: e.g. \"We have obtained the best results with the ….. classifier (parameters=....) , giving classification accuracy of …% on test data….\"\n",
        "*   Comment on the speed of the algorithms and anything else that you deem important/interesting (e.g. confusion matrix)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72KDasqHnt1T",
        "colab_type": "text"
      },
      "source": [
        "# Write your report in this cell\n",
        "\n",
        "..Our dataset(German Credit Data) classifies people as good or bad credit risks according to 20 specified attirbutes. Our aim for this project is developing a decision tree ML model and a kNN ML model to classify people as good or bad credit risks.\n",
        "\n",
        "..Train_data is splitted into %70 training data and %30 validation data. We also have a separate test data.\n",
        "\n",
        "..For decision tree model, we have obtained 66.18357% with our training data.\n",
        "After we fine-tuned our hyper-parameters (min_samples_split = 82), we have obtained 71.49758% accuracy.\n",
        "\n",
        "..For kNN model, we found the bestK in the odd numbers between 1-30 and used that hyper-parameter to achieve the best accuracy. Our best accuracy for kNN model is 70.04831%\n",
        "\n",
        "..To get better accuracies, we used gridsearch to fine-tune more attirbutes. Eventually, we got a better testing accuracy with these hyperparameters.\n",
        "Testing Accuracy = 73.91304%\n",
        "{'criterion': 'entropy', \n",
        "'max_depth': None, \n",
        "'min_samples_split': 54, \n",
        "'splitter': 'random'}"
      ]
    }
  ]
}